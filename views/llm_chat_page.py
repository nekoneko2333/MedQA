"""
LLMé—®ç­”é¡µé¢

åŸºäºRAGå’ŒLLMçš„é—®ç­”ï¼Œä½¿ç”¨çš„æ˜¯deepseekçš„API

"""

import streamlit as st
from advanced.llm_chatbot import LLMChatBot
from utils.llm_context import build_llm_context, build_llm_entity_context, add_to_history, clear_llm_history
from core.chatbot import MedicalChatBot


def render_llm_chat_page():
    st.markdown("### LLMæ™ºèƒ½é—®ç­”")
    
    # é¦–æ¬¡è¿›å…¥é¡µé¢åˆå§‹åŒ–LLMèŠå¤©æœºå™¨äºº
    if 'llm_bot' not in st.session_state:
        # ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®è·å–API
        import os
        api_key = os.getenv("DEEPSEEK_API_KEY", "")
        
        # ä½¿ç”¨è¿æ¥çš„neo4jæ•°æ®åº“
        graph = None
        try:
            if 'bot' in st.session_state and hasattr(st.session_state.bot, 'searcher'):
                if hasattr(st.session_state.bot.searcher, 'g'):
                    graph = st.session_state.bot.searcher.g
        except:
            pass
        
        st.session_state.llm_bot = LLMChatBot(api_key=api_key, graph=graph)
        
        # åˆå§‹åŒ–LLMå¯¹è¯å†å²
        if 'llm_chat_history' not in st.session_state:
            st.session_state.llm_chat_history = []
    
    # APIé…ç½®
    if not st.session_state.llm_bot.llm_client.is_available() or st.session_state.get('show_api_config', False):
        with st.expander("âš™ï¸ APIé…ç½®", expanded=not st.session_state.llm_bot.llm_client.is_available()):
            api_key_input = st.text_input(
                "Deepseek APIå¯†é’¥",
                type="password",
                value=st.session_state.llm_bot.llm_client.api_key if st.session_state.llm_bot.llm_client.api_key else "",
                help="è¯·è¾“å…¥æ‚¨çš„Deepseek APIå¯†é’¥ï¼Œæˆ–è®¾ç½®ç¯å¢ƒå˜é‡DEEPSEEK_API_KEY",
                key="deepseek_api_key_input"
            )
            
            # é…ç½®APIçš„å‘é€ç½‘å€
            with st.expander("URLé…ç½®", expanded=False):
                base_url_input = st.text_input(
                    "APIåŸºç¡€URL",
                    value=st.session_state.llm_bot.llm_client.base_url,
                    help="é»˜è®¤: https://api.deepseek.com/v1",
                    key="deepseek_base_url_input"
                )
                model_input = st.text_input(
                    "æ¨¡å‹åç§°",
                    value=st.session_state.llm_bot.llm_client.model,
                    help="é»˜è®¤: deepseek-chat",
                    key="deepseek_model_input"
                )
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ä¿å­˜é…ç½®", key="save_api_key", type="primary"):
                    if api_key_input:
                        import os
                        os.environ["DEEPSEEK_API_KEY"] = api_key_input
                        if base_url_input:
                            os.environ["DEEPSEEK_API_BASE_URL"] = base_url_input
                        if model_input:
                            os.environ["DEEPSEEK_MODEL"] = model_input
                        
                        # é‡æ–°åˆå§‹åŒ–å®¢æˆ·ç«¯
                        from advanced.llm_client import DeepseekClient
                        new_client = DeepseekClient(
                            api_key=api_key_input,
                            base_url=base_url_input if base_url_input else None,
                            model=model_input if model_input else None
                        )
                        st.session_state.llm_bot.llm_client = new_client
                        st.session_state.show_api_config = False
                        st.success("âœ… APIé…ç½®å·²ä¿å­˜")
                        st.rerun()
                    else:
                        st.error("è¯·è¾“å…¥æœ‰æ•ˆçš„APIå¯†é’¥")
            with col2:
                if st.button("æµ‹è¯•è¿æ¥", key="test_api_connection"):
                    if api_key_input:
                        from advanced.llm_client import DeepseekClient
                        test_client = DeepseekClient(
                            api_key=api_key_input,
                            base_url=base_url_input if base_url_input else None,
                            model=model_input if model_input else None
                        )
                        test_response = test_client.chat(
                            messages=[{"role": "user", "content": "ä½ å¥½"}],
                            max_tokens=50
                        )
                        if 'error' in test_response:
                            st.error(f"âŒ è¿æ¥å¤±è´¥: {test_response.get('error', 'æœªçŸ¥é”™è¯¯')}")
                            if 'error_detail' in test_response:
                                st.text_area("é”™è¯¯è¯¦æƒ…", test_response['error_detail'], height=100, key="error_detail")
                        else:
                            st.success("âœ… è¿æ¥æˆåŠŸï¼")
                            st.text(f"æµ‹è¯•å›å¤: {test_response.get('answer', '')[:100]}")
    
    # æ˜¾ç¤ºAPIçŠ¶æ€
    if st.session_state.llm_bot.llm_client.is_available():
        st.info(f"âœ… APIå·²é…ç½® | æ¨¡å‹: {st.session_state.llm_bot.llm_client.model} | URL: {st.session_state.llm_bot.llm_client.base_url}")
        if st.button("é‡æ–°é…ç½®API", key="reconfig_api"):
            st.session_state.show_api_config = True
            st.rerun()
    
    # æ˜¾ç¤ºå¯¹è¯å†å²
    for idx, msg in enumerate(st.session_state.get('llm_chat_history', [])):
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"], unsafe_allow_html=True)
    
    # å¤„ç†å¾…å‘é€çš„é—®é¢˜
    if st.session_state.get('pending_llm_question'):
        pending = st.session_state.pending_llm_question
        st.session_state.pending_llm_question = None
        with st.chat_message("assistant"):
            with st.spinner("æ€è€ƒä¸­..."):
                # æ„å»ºä¸Šä¸‹æ–‡
                conversation_history = build_llm_context(max_history=10)
                entity_context = build_llm_entity_context()  # æ„å»ºå®ä½“ä¸Šä¸‹æ–‡ç”¨äºè¿½é—®
                
                # è°ƒç”¨LLMèŠå¤©æœºå™¨äºº
                answer_html, classify_result, process_info = st.session_state.llm_bot.chat(
                    question=pending,
                    context=entity_context,  # ä¼ å…¥å®ä½“ä¸Šä¸‹æ–‡
                    conversation_history=conversation_history
                )
                
                # ä¿å­˜åˆ†ç±»ç»“æœåˆ°ä¼šè¯çŠ¶æ€
                if classify_result:
                    st.session_state.llm_last_classify = classify_result
                
                # æ˜¾ç¤ºä¸Šä¸‹æ–‡è§£ææç¤º
                if process_info.get('context_resolved'):
                    orig = process_info['context_resolved']['original']
                    resolved = process_info['context_resolved']['resolved']
                    if orig != resolved:
                        st.caption(f"ğŸ”— å·²ç†è§£è¿½é—®ï¼šã€Œ{orig}ã€â†’ã€Œ{resolved}ã€")
                
                # ä¿å­˜ç­”æ¡ˆ
                add_to_history("assistant", answer_html)
                
                # æ˜¾ç¤ºç­”æ¡ˆ
                st.markdown(answer_html, unsafe_allow_html=True)
                
                # æ˜¾ç¤ºæ£€ç´¢ä¿¡æ¯
                if process_info.get('retrieved_info'):
                    with st.expander("ğŸ“š æ£€ç´¢åˆ°çš„çŸ¥è¯†å›¾è°±ä¿¡æ¯"):
                        st.text(process_info['retrieved_info'])
                
                # æ˜¾ç¤ºå¤„ç†ä¿¡æ¯
                if process_info.get('llm_used'):
                    st.caption("âœ… å·²ä½¿ç”¨LLMç”Ÿæˆå›ç­”")
                else:
                    if 'error' in process_info:
                        st.error(f"âŒ LLMè°ƒç”¨å¤±è´¥: {process_info.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    else:
                        st.caption("âš ï¸ ä½¿ç”¨çŸ¥è¯†å›¾è°±ä¿¡æ¯å›ç­”ï¼ˆLLMä¸å¯ç”¨ï¼‰")
        st.rerun() 
    
    # å¤„ç†æ–°è¾“å…¥çš„é—®é¢˜
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        add_to_history("user", prompt)
        st.session_state.pending_llm_question = prompt
        st.rerun()  
    
    # æ¸…ç©ºå¯¹è¯æŒ‰é’®
    if st.session_state.get('llm_chat_history'):
        if st.button("æ¸…ç©ºå¯¹è¯å†å²", key="clear_llm_history"):
            clear_llm_history()
            st.rerun()

