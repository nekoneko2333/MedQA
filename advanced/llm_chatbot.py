"""
æ¥å…¥LLMçš„åŒ»ç–—é—®ç­”æœºå™¨äºº

- åŸºäºRAGçš„æ£€ç´¢
- ä½¿ç”¨Deepseek API

"""

from typing import List, Dict, Optional
from utils.logger import get_logger
from advanced.llm_client import DeepseekClient
from advanced.rag_retriever import RAGRetriever
from advanced.knowledge_reasoner import KnowledgeReasoner
from nlp.question_classifier import QuestionClassifier
from py2neo import Graph

logger = get_logger(__name__)


class LLMChatBot:
    
    def __init__(self, api_key: Optional[str] = None, graph: Optional[Graph] = None):
        """

        åˆå§‹åŒ–LLMèŠå¤©
        api_key: Deepseek APIå¯†é’¥
        graph: Neo4jå›¾æ•°æ®åº“

        """
        self.llm_client = DeepseekClient(api_key=api_key)
        self.rag_retriever = RAGRetriever(graph=graph)
        self.classifier = QuestionClassifier()  # ç”¨äºå®ä½“æå–
        self.reasoner = KnowledgeReasoner()
        # ç³»ç»Ÿæç¤ºè¯
        self.system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŒ»ç–—åŠ©æ‰‹ï¼ŒåŸºäºæä¾›çš„åŒ»ç–—çŸ¥è¯†å›¾è°±ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
è¦æ±‚ï¼š
1. åŸºäºæä¾›çš„çŸ¥è¯†å›¾è°±ä¿¡æ¯å›ç­”é—®é¢˜ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯
2. å¦‚æœçŸ¥è¯†å›¾è°±ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œæ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·
3. å›ç­”è¦ä¸“ä¸šã€å‡†ç¡®ã€æ˜“æ‡‚
4. å¯¹äºåŒ»ç–—å»ºè®®ï¼Œè¦æé†’ç”¨æˆ·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ
5. ä½¿ç”¨ä¸­æ–‡å›ç­”

çŸ¥è¯†å›¾è°±ä¿¡æ¯ä¼šä»¥ä»¥ä¸‹æ ¼å¼æä¾›ï¼š
[çŸ¥è¯†å›¾è°±ä¿¡æ¯]
...
[/çŸ¥è¯†å›¾è°±ä¿¡æ¯]
"""
    
    def chat(self, question: str, context: Optional[Dict] = None, 
             conversation_history: Optional[List[Dict]] = None) -> tuple:
        """
        å¤„ç†ç”¨æˆ·é—®é¢˜å¹¶ç”Ÿæˆå›ç­”
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            conversation_history: å¯¹è¯å†å²åˆ—è¡¨
        
        Returns:
            (answer_html, metadata, process_info) å…ƒç»„
        """
        process_info = {
            'method': 'llm_rag',
            'retrieved_info': None,
            'llm_used': False,
            'error': None
        }
        
        # è§£æä¸Šä¸‹æ–‡ï¼Œå¤„ç†è¿½é—®å’Œä»£è¯
        resolved_question = self._resolve_context(question, context)
        if resolved_question != question:
            process_info['context_resolved'] = {
                'original': question,
                'resolved': resolved_question
            }
            question = resolved_question  # ä½¿ç”¨è§£æåçš„é—®é¢˜
        
        # åœ¨RAGæ£€ç´¢ä¹‹å‰å…ˆæ£€æµ‹å¤šè·³æ¨ç†
        reasoning_result = None
        if self.reasoner:
            try:
                reasoning_result = self.reasoner.execute_reasoning(question)
                if reasoning_result and reasoning_result.get('success'):
                    # å¤šè·³æ¨ç†æˆåŠŸï¼Œä½¿ç”¨æ¨ç†ç»“æœ
                    process_info['method'] = 'reasoning_llm'
                    process_info['reasoning'] = {
                        'type': reasoning_result['hop_info']['type'],
                        'description': reasoning_result['hop_info']['description'],
                        'path': reasoning_result['reasoning_path']
                    }
                    # å°†æ¨ç†ç»“æœä½œä¸ºæ£€ç´¢ä¿¡æ¯
                    retrieved_info = reasoning_result['answer']
                    process_info['retrieved_info'] = retrieved_info
                    process_info['reasoning_used'] = True
                    
                    # æå–å®ä½“
                    classify_result = self.classifier.classify(question)
                    entities = classify_result.get('args', {}) if classify_result else {}
                    
                    # æ„å»ºæ¶ˆæ¯å¹¶è°ƒç”¨LLM
                    messages = self._build_messages(question, retrieved_info, conversation_history, is_reasoning=True)
                    
                    if not self.llm_client.is_available():
                        # LLMä¸å¯ç”¨ï¼Œç›´æ¥è¿”å›æ¨ç†ç»“æœ
                        answer_html = self._format_reasoning_answer(reasoning_result['answer'], reasoning_result)
                        return answer_html, classify_result, process_info
                    
                    llm_response = self.llm_client.chat(
                        messages=messages,
                        temperature=0.7,
                        max_tokens=2000
                    )
                    
                    if 'error' in llm_response:
                        # LLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æ¨ç†ç»“æœä½œä¸ºfallback
                        error_msg = llm_response.get('error', 'æœªçŸ¥é”™è¯¯')
                        process_info['error'] = error_msg
                        logger.warning(f"LLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æ¨ç†ç»“æœ: {error_msg}")
                        answer_html = self._format_reasoning_answer(reasoning_result['answer'], reasoning_result)
                        error_hint = f"<div style='color: orange; margin-bottom: 10px;'>âš ï¸ LLMæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œä»¥ä¸‹æ˜¯åŸºäºçŸ¥è¯†æ¨ç†çš„ç»“æœï¼š</div>"
                        return error_hint + answer_html, classify_result, process_info
                    
                    process_info['llm_used'] = True
                    answer = llm_response.get('answer', '')
                    answer_html = self._format_answer(answer)
                    
                    # æ·»åŠ æ¨ç†è·¯å¾„æç¤º
                    reasoning_hint = self._format_reasoning_hint(reasoning_result)
                    answer_html = reasoning_hint + answer_html
                    
                    return answer_html, classify_result, process_info
            except Exception as e:
                logger.warning(f"çŸ¥è¯†æ¨ç†æ£€æµ‹å¤±è´¥: {e}")
                # ç»§ç»­ä½¿ç”¨RAGæ£€ç´¢
        
        # å¦‚æœä¸æ˜¯å¤šè·³æ¨ç†ï¼Œä½¿ç”¨RAGæ£€ç´¢
        # æå–å®ä½“
        classify_result = self.classifier.classify(question)
        entities = classify_result.get('args', {}) if classify_result else {}
        
        # RAGæ£€ç´¢
        retrieved_info = self.rag_retriever.retrieve(question, entities=entities)
        process_info['retrieved_info'] = retrieved_info
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = self._build_messages(question, retrieved_info, conversation_history)
        
        # è°ƒç”¨LLM
        if not self.llm_client.is_available():
            return self._fallback_answer(question, retrieved_info, entities), classify_result, process_info
        
        llm_response = self.llm_client.chat(
            messages=messages,
            temperature=0.7,
            max_tokens=2000
        )
        
        if 'error' in llm_response:
            # LLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨fallbackï¼Œä½†æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            error_msg = llm_response.get('error', 'æœªçŸ¥é”™è¯¯')
            error_detail = llm_response.get('error_detail', '')
            process_info['error'] = error_msg
            process_info['error_detail'] = error_detail
            logger.error(f"LLMè°ƒç”¨å¤±è´¥: {error_msg}")
            if error_detail:
                logger.debug(f"é”™è¯¯è¯¦æƒ…: {error_detail}")
            
            # å¦‚æœæœ‰æ£€ç´¢ä¿¡æ¯ï¼Œä½¿ç”¨fallbackï¼›å¦åˆ™æ˜¾ç¤ºé”™è¯¯
            if retrieved_info:
                fallback_answer = self._fallback_answer(question, retrieved_info, entities)
                # åœ¨fallbackç­”æ¡ˆå‰æ·»åŠ é”™è¯¯æç¤º
                error_hint = f"<div style='color: orange; margin-bottom: 10px;'>âš ï¸ LLMæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ ({error_msg})ï¼Œä»¥ä¸‹æ˜¯åŸºäºçŸ¥è¯†å›¾è°±çš„ä¿¡æ¯ï¼š</div>"
                return error_hint + fallback_answer, classify_result, process_info
            else:
                error_answer = f"<div>æŠ±æ­‰ï¼Œæš‚æ—¶æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ã€‚<br><br>é”™è¯¯ä¿¡æ¯: {error_msg}<br>è¯·æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®ï¼Œæˆ–å°è¯•ä½¿ç”¨ã€Œæ™ºèƒ½é—®ç­”ã€åŠŸèƒ½ã€‚</div>"
                if error_detail:
                    error_answer += f"<br><br><details><summary>è¯¦ç»†é”™è¯¯ä¿¡æ¯</summary><pre>{error_detail[:500]}</pre></details>"
                return error_answer, classify_result, process_info
        
        process_info['llm_used'] = True
        answer = llm_response.get('answer', '')
        answer_html = self._format_answer(answer)
        
        return answer_html, classify_result, process_info
    
    def _build_messages(self, question: str, retrieved_info: str, 
                       conversation_history: Optional[List[Dict]] = None,
                       is_reasoning: bool = False) -> List[Dict[str, str]]:
        """æ„å»ºLLMæ¶ˆæ¯åˆ—è¡¨"""
        messages = [
            {"role": "system", "content": self.system_prompt}
        ]
        
        # æ·»åŠ å¯¹è¯å†å²ï¼Œæœ€è¿‘6æ¡æ¶ˆæ¯
        if conversation_history:
            for msg in conversation_history[-6:]: 
                messages.append({
                    "role": msg.get('role', 'user'),
                    "content": msg.get('content', '')[:500]  
                })
        
        # æ·»åŠ æ£€ç´¢åˆ°çš„ä¿¡æ¯æˆ–æ¨ç†ç»“æœ
        if is_reasoning:
            # å¤šè·³æ¨ç†ç»“æœ
            context_content = f"[çŸ¥è¯†æ¨ç†ç»“æœ]\n{retrieved_info}\n[/çŸ¥è¯†æ¨ç†ç»“æœ]\n\n"
            context_content += "æ³¨æ„ï¼šä»¥ä¸Šæ˜¯é€šè¿‡å¤šè·³æ¨ç†å¾—åˆ°çš„ç»“æœï¼Œè¯·åŸºäºè¿™äº›ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\n\n"
        else:
            # RAGæ£€ç´¢ç»“æœ
            if retrieved_info:
                context_content = f"[çŸ¥è¯†å›¾è°±ä¿¡æ¯]\n{retrieved_info}\n[/çŸ¥è¯†å›¾è°±ä¿¡æ¯]\n\n"
            else:
                context_content = "[çŸ¥è¯†å›¾è°±ä¿¡æ¯]\næœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯\n[/çŸ¥è¯†å›¾è°±ä¿¡æ¯]\n\n"
        
        # æ·»åŠ å½“å‰é—®é¢˜
        user_message = context_content + f"ç”¨æˆ·é—®é¢˜: {question}"
        messages.append({"role": "user", "content": user_message})
        
        return messages
    
    def _format_answer(self, answer: str) -> str:
        """
        å°†Markdownæ ¼å¼è½¬æ¢ä¸ºHTMLï¼Œä½¿å…¶æ˜¾ç¤ºæ›´ç¾è§‚
        """
        import markdown
        from markdown.extensions import fenced_code, tables, nl2br
        
        # é…ç½®Markdownæ‰©å±•
        md = markdown.Markdown(extensions=[
            'fenced_code',
            'tables',
            'nl2br',
            'extra'
        ])
        
        # è½¬æ¢ä¸ºHTML
        html = md.convert(answer)
        
        # æ·»åŠ æ ·å¼ï¼Œä½¿Markdownæ¸²æŸ“æ›´ç¾è§‚
        styled_html = f"""
        <div style="line-height: 1.6; color: var(--text-main, #333);">
            {html}
        </div>
        <style>
            div h1, div h2, div h3 {{
                margin-top: 1em;
                margin-bottom: 0.5em;
                font-weight: 600;
                color: var(--text-main, #2c3e50);
            }}
            div h1 {{ font-size: 1.5em; }}
            div h2 {{ font-size: 1.3em; }}
            div h3 {{ font-size: 1.1em; }}
            div p {{
                margin-bottom: 0.8em;
                line-height: 1.6;
            }}
            div ul, div ol {{
                margin-left: 1.5em;
                margin-bottom: 0.8em;
            }}
            div li {{
                margin-bottom: 0.4em;
            }}
            div strong {{
                font-weight: 600;
                color: var(--text-main, #2c3e50);
            }}
            div code {{
                background-color: rgba(0, 0, 0, 0.05);
                padding: 2px 6px;
                border-radius: 3px;
                font-family: 'Courier New', monospace;
                font-size: 0.9em;
            }}
            div pre {{
                background-color: rgba(0, 0, 0, 0.05);
                padding: 10px;
                border-radius: 5px;
                overflow-x: auto;
                margin-bottom: 0.8em;
            }}
            div blockquote {{
                border-left: 3px solid var(--primary-color, #5B7AA6);
                padding-left: 1em;
                margin-left: 0;
                color: var(--text-secondary, #666);
                font-style: italic;
            }}
        </style>
        """
        return styled_html
    
    def _resolve_context(self, question: str, context: Optional[Dict] = None) -> str:
        """
        è§£æä¸Šä¸‹æ–‡ï¼Œå¤„ç†ä»£è¯å’Œè¿½é—®,å’Œchatbotç±»ä¼¼
        """
        if not context:
            return question
        
        # è¿½é—®å…³é”®è¯
        followup_patterns = [
            ('å®ƒ', 'è¿™ä¸ªç—…', 'è¿™ç§ç—…', 'è¯¥ç—…', 'è¿™ä¸ªç—‡çŠ¶', 'è¿™ä¸ª'),  
            ('æ€ä¹ˆé¢„é˜²', 'å¦‚ä½•é¢„é˜²', 'é¢„é˜²æ–¹æ³•', 'æ€ä¹ˆé¢„é˜²'),
            ('æ€ä¹ˆæ²»ç–—', 'å¦‚ä½•æ²»ç–—', 'æ²»ç–—æ–¹æ³•', 'æ€ä¹ˆåŠ', 'å’‹åŠ', 'æ€ä¹ˆæ²»'),
            ('åƒä»€ä¹ˆè¯', 'ç”¨ä»€ä¹ˆè¯', 'æœ‰ä»€ä¹ˆè¯', 'è¯¥åƒä»€ä¹ˆè¯', 'èƒ½åƒä»€ä¹ˆè¯'),
            ('åƒä»€ä¹ˆå¥½', 'èƒ½åƒä»€ä¹ˆ', 'é¥®é£Ÿ', 'åº”è¯¥åƒä»€ä¹ˆ', 'å¯ä»¥åƒä»€ä¹ˆ'),
            ('ä¸èƒ½åƒä»€ä¹ˆ', 'å¿Œå£', 'ç¦å¿Œ', 'ä¸èƒ½åƒ', 'å¿Œä»€ä¹ˆ'),
            ('æœ‰ä»€ä¹ˆç—‡çŠ¶', 'ç—‡çŠ¶æ˜¯ä»€ä¹ˆ', 'ä»€ä¹ˆè¡¨ç°', 'æœ‰å“ªäº›ç—‡çŠ¶'),
            ('æŒ‚ä»€ä¹ˆç§‘', 'çœ‹ä»€ä¹ˆç§‘', 'å»ä»€ä¹ˆç§‘', 'è¯¥æŒ‚ä»€ä¹ˆç§‘'),
            ('ä»€ä¹ˆåŸå› ', 'æ€ä¹ˆå¼•èµ·', 'ä¸ºä»€ä¹ˆä¼š', 'æ˜¯ä»€ä¹ˆåŸå› '),
            ('åšä»€ä¹ˆæ£€æŸ¥', 'éœ€è¦æ£€æŸ¥ä»€ä¹ˆ', 'è¦åšä»€ä¹ˆæ£€æŸ¥', 'æ£€æŸ¥ä»€ä¹ˆ'),
        ]
        
        last_disease = context.get('last_disease')
        last_symptom = context.get('last_symptom')
        
        resolved = question
        
        # æ›¿æ¢ä»£è¯
        if last_disease:
            for pronoun in ['å®ƒ', 'è¿™ä¸ªç—…', 'è¿™ç§ç—…', 'è¯¥ç—…', 'è¿™ç—…', 'è¿™ä¸ª']:
                if pronoun in resolved:
                    resolved = resolved.replace(pronoun, last_disease)
                    return resolved
        elif last_symptom:
            for pronoun in ['å®ƒ', 'è¿™ä¸ªç—‡çŠ¶', 'è¿™ä¸ª']:
                if pronoun in resolved:
                    resolved = resolved.replace(pronoun, last_symptom)
                    return resolved
        
        # æ²¡æœ‰æ˜ç¡®å®ä½“çš„é—®å¥ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯è¿½é—®
        has_entity = False
        try:
            test_classify = self.classifier.classify(question)
            if test_classify and test_classify.get('args'):
                has_entity = True
        except:
            pass
        
        # å¦‚æœæ²¡æœ‰å®ä½“ï¼Œå°è¯•è¡¥å……ä¸Šä¸‹æ–‡ä¸­çš„å®ä½“
        if not has_entity:
            # æ£€æŸ¥æ˜¯å¦æ˜¯è¿½é—®æ¨¡å¼
            for patterns in followup_patterns:
                for pattern in patterns:
                    if pattern in question:
                        # ä¼˜å…ˆä½¿ç”¨ç–¾ç—…
                        if last_disease:
                            # åœ¨é—®å¥å¼€å¤´æˆ–åˆé€‚ä½ç½®è¡¥å……ç–¾ç—…å
                            if question.startswith(pattern):
                                resolved = f"{last_disease}{question}"
                            else:
                                resolved = f"{last_disease}{question}"
                            return resolved
                        # å¦‚æœæ²¡æœ‰ç–¾ç—…ï¼Œä½¿ç”¨ç—‡çŠ¶
                        elif last_symptom:
                            # åœ¨é—®å¥å¼€å¤´æˆ–åˆé€‚ä½ç½®è¡¥å……ç—‡çŠ¶å
                            if question.startswith(pattern):
                                resolved = f"{last_symptom}{question}"
                            else:
                                resolved = f"{last_symptom}{question}"
                            return resolved
        
        return resolved
    
    def _fallback_answer(self, question: str, retrieved_info: str, entities: Dict) -> str:
        """LLMä¸å¯ç”¨æ—¶çš„fallbackå›ç­”"""
        if retrieved_info:
            return f"<div>åŸºäºçŸ¥è¯†å›¾è°±ä¿¡æ¯ï¼š<br><br>{retrieved_info.replace(chr(10), '<br>')}</div>"
        else:
            return "<div>æŠ±æ­‰ï¼Œæš‚æ—¶æ— æ³•å›ç­”æ‚¨çš„é—®é¢˜ã€‚è¯·å°è¯•ä½¿ç”¨ã€Œæ™ºèƒ½é—®ç­”ã€åŠŸèƒ½ã€‚</div>"
    
    def _format_reasoning_answer(self, answer: str, reasoning_result: Dict) -> str:
        """æ ¼å¼åŒ–æ¨ç†ç»“æœä¸ºHTML"""
        # å…ˆæ ¼å¼åŒ–Markdown
        formatted = self._format_answer(answer)
        return formatted
    
    def _format_reasoning_hint(self, reasoning_result: Dict) -> str:
        """æ ¼å¼åŒ–æ¨ç†è·¯å¾„æç¤º"""
        hop_info = reasoning_result.get('hop_info', {})
        reasoning_path = reasoning_result.get('reasoning_path', [])
        
        # æ„å»ºæ¨ç†é“¾è·¯å±•ç¤º
        chain_display = ""
        if reasoning_path:
            steps_html = []
            for step in reasoning_path:
                step_num = step.get('step', '?')
                action = step.get('action', '')
                relation = step.get('relation', '')
                result = step.get('result', [])
                
                if isinstance(result, list):
                    result_str = ', '.join(str(r)[:20] for r in result[:3])
                    if len(result) > 3:
                        result_str += '...'
                else:
                    result_str = str(result)[:50]
                
                steps_html.append(
                    f"<div style='padding:5px 10px; background:var(--card-bg, #F8F9FA); border-radius:4px; margin:3px 0;'>"
                    f"<span style='color:var(--primary-color, #5B7AA6); font-weight:bold;'>Step {step_num}</span>: {action}"
                    f"<span style='color:var(--text-secondary, #888); font-size:0.9em;'> ({relation})</span>"
                    f"</div>"
                )
            chain_display = ''.join(steps_html)
        
        # ç»„åˆæœ€ç»ˆè¾“å‡º
        header_html = f"""
        <div style="background:linear-gradient(135deg, #667eea11 0%, #764ba211 100%); 
                    border-left:4px solid #667eea; padding:12px; border-radius:8px; margin-bottom:15px;">
            <div style="font-size:0.9em; color:#667eea; margin-bottom:5px;">
                ğŸ”— <strong>çŸ¥è¯†æ¨ç†</strong> Â· {hop_info.get('description', 'å¤šè·³æŸ¥è¯¢')}
            </div>
            {chain_display}
        </div>
        """
        
        return header_html

